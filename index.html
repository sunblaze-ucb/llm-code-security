
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- Here are the current paper tags:
1) tag-all (for all papers)
2) tag-privacy
3) tag-host-security
4) tag-network-security
5) tag-theoretical-foundations


-->
<html><head>
<title>Deep Learning for Program Synthesis</title>
<style type="text/css">
body {
    margin-top: 30px;
    margin-bottom: 30px;
    margin-left: 100px;
    margin-right: 100px;
}
p {
    margin-top: 0px;
    margin-bottom: 0px;
}

.caption {
    font-size: 34px;
    font-weight: normal;
    color: #000;
    font-family: Constantia, "Lucida Bright", "DejaVu Serif", Georgia, serif;
}
.caption-1 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
}
.caption-2 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    font-weight: bold;
    color: #990000;
}
.caption-3 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    font-weight: bold;
    color: #F00;
}

.caption-4 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    color: #990000;
}
.content {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    text-align: justify;
}

.title-small {
    font-size: 20px;
    font-family: Georgia, "Times New Roman", Times, serif;
    font-weight: bold;
    color: #F90;
}
.title-large {
    font-size: 28px;
    font-family: Georgia, "Times New Roman", Times, serif;
    font-weight: bold;
    color: #000;
}
.margin {
    font-size: 10px;
    line-height: 10px;
}
.margin-small {
    font-size: 5px;
    line-height: 5px;
}
.margin-large {
    font-size: 16px;
    line-height: 16px;
}
</style>
<script type="text/javascript" src="jquery.js"></script>     
<script type="text/javascript"> 

function displaypage(){
	$(".tag-all").hide();
	if(document.getElementById('tag-all-box').checked){
		$(".tag-all").show();
	}
	if(document.getElementById('tag-theoretical-foundations-box').checked){
		$(".tag-theoretical-foundations").show();
	}
	if(document.getElementById('tag-host-security-box').checked){
		$(".tag-host-security").show();
	}
	if(document.getElementById('tag-network-security-box').checked){
		$(".tag-network-security").show();
	}
	if(document.getElementById('tag-privacy-box').checked){
		$(".tag-privacy").show();
	}

}

$(document).ready(function() {    

$("#tag-all-box").click(function() {
	displaypage();
});   
$("#tag-theoretical-foundations-box").click(function() {
	displaypage();
});
$("#tag-host-security-box").click(function() {
	displaypage();
}); 
$("#tag-network-security-box").click(function() {
	displaypage();
}); 
$("#tag-privacy-box").click(function() {
	displaypage();
}); 

});             
</script>     
<meta content="text/html; charset=unicode" http-equiv="Content-Type">
<meta name="GENERATOR" content="MSHTML 9.00.8112.16443"></head>
<body><center><h1><span>Deep Learning for Program Synthesis</span></h1></center>

<center>
		[<a href="#statement">Research Statement</a>] [<a href ="#publications">Publications</a>] [<a href="#members">Members</a>]  
</center>

<h2 class="label"><a name="statement"><span >Research Statement</span></a></h2> 
 
Synthesizing a program from a specification has been a long-standing challenge. Recent research have demonstrated that deep neural networks have the potential to learn a program satisfying various spefication methods, such as natural language descriptions and input-output examples. The ability to automatically synthesize code has numerous applications, ranging from helping end-users (non-technical users) write programs, helping software developers synthesize mundane pieces of code or optimized code, helping data scientists clean up and explore data, to helping algorithm designers discover new algorithms.

<br><br>

 This problem is extremely challenging, and the complexity of the synthesized programs by existing approaches is still limited. In our research for neural program synthesis, we aim at generating programs with more complexity, better generalizability, while guaranteeing the correctness. In this process, besides enabling real-world applications using program synthesis, we hope to make contributions towards addressing core challenges in deep learning including generalization, search, abstraction, and representation. We believe that solving the program synthesis problem is a good step towards solving AGI (artificial general intelligence).

<hr>

<h2 class="label"><a name="publications"><span >Recent Publications</span></a></h2>

<!--<form> 
  <div id="tags"> 
    <input type="radio" name="tags" checked id="tag-all-box"> 
    <label for="tag-all-box">All Publications</label> 
   
    <input type="radio" name="tags" id="tag-theoretical-foundations-box"> 
    <label for="tag-theoretical-foundations-box">Theoretical Foundations</label>
 
    <input type="radio" name="tags" id="tag-host-security-box">
    <label for="tag-host-security-box">Host Security</label> 
    
    <input type="radio" name="tags" id="tag-network-security-box"> 
    <label for="tag-network-security-box">Network Security</label> 
    
    <input type="radio" name="tags" id="tag-privacy-box"> 
    <label for="tag-privacy-box">Privacy</label> 
    
  </div> 
</form> -->

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="imgs/tree2tree.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1802.03691"><strong>Tree-to-tree Neural Networks for Program Translation</strong></a></p>
      <p class="content">Xinyun Chen, Chang Liu, Dawn Song.</p>
      <p class="content">Workshop of International Conference on Learning Representations (ICLR). January, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="imgs/neuralParser.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1706.01284"><strong>Towards Synthesizing Complex Programs from Input-Output Examples</strong></a></p>
      <p class="content">Xinyun Chen, Chang Liu, Dawn Song.</p>
      <p class="content">International Conference on Learning Representations (ICLR). January, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="imgs/php.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://openreview.net/forum?id=rJl63fZRb"><strong>Parametrized Hierarchical Procedures for Neural Programming</strong></a></p>
      <p class="content">Roy Fox, Richard Shin, Sanjay Krishnan, Ken Goldberg, Dawn Song, Ion Stoica.</p>
      <p class="content">International Conference on Learning Representations (ICLR). January, 2018.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="imgs/sqlnet.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1711.04436"><strong>SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning</strong></a></p>
      <p class="content">Xiaojun Xu, Chang Liu, Dawn Song.</p>
      <p class="content">November, 2017.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="imgs/recursion.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1704.06611"><strong>Making Neural Programming Architectures Generalize via Recursion</strong></a></p>
      <p class="content">Jonathon Cai, Richard Shin, Dawn Song.</p>
      <p class="content">International Conference on Learning Representations (ICLR). April, 2017. <em><strong><font color="red">Best Paper Award</font></strong></em></p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<table border="0" cellpadding="0" cellspacing="15" width="100%">
  <tbody><tr>
    <td width="200"><img src="imgs/latent-attention.png" border="1"width="210"></a></td>
    <td width="20"></td>
    <td valign="middle" width="800"><p class="content"><a href="https://arxiv.org/abs/1611.01867"><strong>Latent Attention For If-Then Program Synthesis</strong></a></p>
      <p class="content">Xinyun Chen, Chang Liu, Richard Shin, Dawn Song, Mingcheng Chen.</p>
      <p class="content">Advances in Neural Information Processing Systems (NIPS). December, 2016.</p>
     <p class="margin-small">&nbsp;</p>
      </tr>
</tbody></table>

<hr>



<h2 class="label"><a name="members"><span >Members</span></a></h2>

<ul>
 <li>
  <p class="content"><b>Faculty:</b> <a href="http://www.cs.berkeley.edu/~dawnsong/">Dawn Song</a></p>
 </li><br>
  <li><p class="content"><b>Postdocs:</b></p><ul>
    <li><p class="content"><a href="https://people.eecs.berkeley.edu/~liuchang/">Chang Liu</a></p></li>
  </ul><br></li>

  <li><p class="content"><b>Ph.D. Students:</b></p>
  <ul>
    <li><p class="content"><a href="https://people.eecs.berkeley.edu/~ricshin/">Richard Shin</a></p></li>
    <li><p class="content">Xinyun Chen</p></li>
  </ul>
  <br>
  </li>
</li>
</ul>
<br><br></body></html>
